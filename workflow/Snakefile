configfile: "config/config.yaml"
import glob  # Collects file paths using flexible search patterns

# Define a variable for the output directory
output_dir = config["output_dir"]

rule all:
    # Specifies the final output files for the workflow
    input:
        # Tables --------------------------------------------------------------
        final_patient_table = f"{output_dir}/all_patient_unique_with_ecc_hif1a_gex.txt", 
        # Patient data table with ECC score, HIF1A activation score, and GEX data
        
        gmm_table = f"{output_dir}/gmm_table.txt",
        # Gaussian mixture table for calculating fold change nuclear area of ECCs

        all_cells_detection = f"{output_dir}/all_cells_area.txt",
        # Nuclear area of all detections from QuPath

        ecc_fold_change = f"{output_dir}/ecc_fold_change.txt",
        # Calculation of the fold change nuclear area of the ECCs

        # Plots ---------------------------------------------------------------
        fold_change_plot = f"{output_dir}/plots/ecc_fc_scatterplot.tif"
        # surv_curve = f"{output_dir}/plots/survival_km_plot_all_grades.tif",
        # rec_curve = f"{output_dir}/plots/overall_rec_km_plot_all_grades.tif",
        # hr_surv = f"{output_dir}/hr/os_with_grade.csv",
        # hr_rec = f"{output_dir}/hr/or_with_grade.csv"


rule merge_manual_score:
    # Combines all manual scoring CSV files into a single complete results file.
    input:
        sorted(glob.glob(config["input_files"]["manual_scores"])) 
        # Collects and sorts all CSV files with manual scores from the "resources/ManualScores" directory
    output:
        "resources/complete_patho_results.csv" # Combined output of all scoring files
    shell:
        """
        # Combine input CSV files, skipping headers after the first file.
        awk 'BEGIN {{FS=OFS="\t"}} \
        FNR == 1 && NR != 1 {{next}} \
        {{print $1,$2,$3}}' \
        {input} > {output}
        """


rule ecc_patient_data:
    # Parses patient data and maps TMA cores with ECC information.
    input:
        patient_file = config["input_files"]["patient_file"],  # Original patient data file
        tma_map = config["input_files"]["tma_map"],  # TMA mapping file
        patho_score = "resources/complete_patho_results.csv"  # Combined manual scoring results
    output:
        patient_cores = f"{output_dir}/patient_with_core_ecc.txt",  # Patient data with mapped TMA cores and ECC
        patient_ecc = f"{output_dir}/all_patient_unique_with_ecc.txt"  # Unique patient data with ECC
    script:
        "scripts/patient_data_parsers/patient_data_parser.py"  # Python script for processing


rule prepare_hif1a_file:
    """
    Merge and process the hif1a data from the multiple tables.
    The bash script consists in three steps:
    First, merges all files. 
    Second step, selects only the HIF1A columns.
    The last step, merges the two pathologist scores, keeping only the highest
    score for each patient.
    """
    input:
        immuno_tables = glob.glob(config["input_files"]["immuno_tables"])
        # Collects and sorts all CSV files with Immunology stains scores from the "resources/ImmunoStainings" directory 

    output:
        hif1a_data = "resources/hif_scores_merged.csv"
    
    shell:
        """
        bash scripts/patient_data_parsers/process_hif1a_scores.sh {output} {input}
        """


rule hif_activation:
    # Adds the hif1A activation score to the patient table.
    input:
        patient_cores = f"{output_dir}/patient_with_core_ecc.txt", # File containing the patient core location
        patient_ecc = f"{output_dir}/all_patient_unique_with_ecc.txt", # File that the HIF1A activation will be added.
        hif1a_data = "resources/hif_scores_merged.csv" # File containing the hif1a data
    
    output:
        f"{output_dir}/all_patient_unique_with_ecc_hif1a.txt"

    script:
        "scripts/r_scripts/hif1a_pacc.R"


rule prepare_gex_file:
    '''
    Parses the original gene expression data table to isolate only the 
    interesting columns.
    Here the columns are: patient number (46057), cdk1 (6078), epas1 (10708),
    hif1a (13533), and mki67(18766).

    To see a list of headers use: head -1 resources/GEX_46k_with_gene_names.csv | \
    tr ',' '\n' | cat -n
    '''
    input:
        original_gex = config["input_files"]["original_gex"]
    
    output:
        gex = "resources/gex_interesting_genes.csv"
    
    shell:
        """
        awk -F "," 'BEGIN {{OFS="\t"}} {{print $46057,$6078,$10708,$13533,$18766}}' \
        {input.original_gex} | \
        sed 's/\r//g' > {output}
        """

rule gene_expression:
    # Adds the gene expression values to the patient data table.
    input: 
        patient_hif = f"{output_dir}/all_patient_unique_with_ecc_hif1a.txt", # patient data file with HIF1A activation data
        gex = "resources/gex_interesting_genes.csv", # Gene expression data of the selected genes.
        script = "scripts/patient_data_parsers/merge_gene_expression.awk" # script to merge by patient number.
    
    output:
        f"{output_dir}/all_patient_unique_with_ecc_hif1a_gex.txt"
    
    shell:
        """
        awk -f {input.script} {input.gex} {input.patient_hif} > {output}
        """


rule gmm_table:
    """
    Fits a two-component gaussian mixture model in all files generated in the 
    QuPath detection and generates a table with the mean of each component. 
    """
    input:
        sorted(glob.glob(config["input_files"]["detection_tables"]))
    
    output:
        f"{output_dir}/gmm_table.txt"
    
    script:
        "scripts/r_scripts/gaussian_mixture.R"


rule detection_table:
    # Merge the detection files created by QuPath
    input:
        sorted(glob.glob(config["input_files"]["detection_tables"]))
    output: 
        f"{output_dir}/all_cells_area.txt"
    shell:
        """
        awk 'BEGIN {{FS=OFS="\t"; print "Parent","Image","Area"}} 
        FNR == 1 {{next}} 
        {{
        fname = FILENAME;
        sub(/^.*\\//, "", fname);  # remove the path of the file
        print fname,$1,$6}}' {input} > {output}
        """


rule merge_ecc_sizes:
    # Merges all the files with ECC sizes
    input:
        sorted(glob.glob(config["input_files"]["ecc_sizes"]))
    output:
        f"{output_dir}/merged_ecc_sizes.txt"
    shell:
        """
        awk 'FNR == 1 && NR != 1 {{next}}
        {{print $0}}' {input} > {output}        
        """


rule ecc_fold_change:
    # Calculates the fold change for each ECC detected by the pathologists
    input:
        gmm_table = f"{output_dir}/gmm_table.txt",
        merged_ecc_sizes = f"{output_dir}/merged_ecc_sizes.txt"
    output:
        f"{output_dir}/ecc_fold_change.txt"
    script:
        "scripts/patient_data_parsers/manual_scoring_sizes.py"


rule fold_change_plot:
    # Generates a scatterplot with the ecc nuclear area fold change
    input:
        gmm_table = f"{output_dir}/gmm_table.txt",
        ecc_fold_change= f"{output_dir}/ecc_fold_change.txt",
        all_cells_area = f"{output_dir}/all_cells_area.txt"
    output:
        f"{output_dir}/plots/ecc_fc_scatterplot.tif"
    script:
        "scripts/r_scripts/fold_change_plots.R"