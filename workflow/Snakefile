import glob  # Collects file paths using flexible search patterns


rule all:
    # Specifies the final output files for the workflow
    input:
        final_patient_table = "results/all_patient_unique_with_ecc_hif1a_gex.txt", 
        # Patient data table with ECC score, HIF1A activation score, and GEX data
        
        gmm_table = "results/gmm_table.txt",
        # Gaussian mixture table for calculating fold change nuclear area of ECCs

        all_cells_detection = "results/all_cells_area.txt"
        # surv_curve = "results/plots/survival_km_plot_all_grades.tif",
        # rec_curve = "results/plots/overall_rec_km_plot_all_grades.tif",
        # hr_surv = "results/hr/os_with_grade.csv",
        # hr_rec = "results/hr/or_with_grade.csv"


rule merge_manual_score:
    # Combines all manual scoring CSV files into a single complete results file.
    input:
        sorted(glob.glob("resources/ManualScores/*_scores.csv")) 
        # Collects and sorts all CSV files with manual scores from the "resources/ManualScores" directory
    output:
        "resources/complete_patho_results.csv" # Combined output of all scoring files
    shell:
        """
        # Combine input CSV files, skipping headers after the first file.
        awk 'BEGIN {{FS=OFS="\t"}} \
        FNR == 1 && NR != 1 {{next}} \
        {{print $1,$2,$3}}' \
        {input} > {output}
        """


rule ecc_patient_data:
    # Parses patient data and maps TMA cores with ECC information.
    input:
        patient_file = "resources/SB91RT_final_20170821_PrimoLR_EjPnr_orginal.csv",  # Original patient data file
        tma_map = "resources/Koppling_PathXL_till_TMA-nr.csv",  # TMA mapping file
        patho_score = "resources/complete_patho_results.csv"  # Combined manual scoring results
    output:
        patient_cores = "results/patient_with_core_ecc.txt",  # Patient data with mapped TMA cores and ECC
        patient_ecc = "results/all_patient_unique_with_ecc.txt"  # Unique patient data with ECC
    script:
        "scripts/patient_data_parsers/patient_data_parser.py"  # Python script for processing


rule prepare_hif1a_file:
    """
    Merge and process the hif1a data from the multiple tables.
    The bash script consists in three steps:
    First, merges all files. 
    Second step, selects only the HIF1A columns.
    The last step, merges the two pathologist scores, keeping only the highest
    score for each patient.
    """
    input:
        immuno_tables = glob.glob("resources/ImmunoStainings/SWEBCG_pathXL_export_all_230405*.csv")
        # Collects and sorts all CSV files with Immunology stains scores from the "resources/ImmunoStainings" directory 

    output:
        hif1a_data = "resources/hif_scores_merged.csv"
    
    shell:
        """
        bash scripts/patient_data_parsers/process_hif1a_scores.sh {output} {input}
        """


rule hif_activation:
    # Adds the hif1A activation score to the patient table.
    input:
        patient_cores = "results/patient_with_core_ecc.txt", # File containing the patient core location
        patient_ecc = "results/all_patient_unique_with_ecc.txt", # File that the HIF1A activation will be added.
        hif1a_data = "resources/hif_scores_merged.csv" # File containing the hif1a data
    
    output:
        "results/all_patient_unique_with_ecc_hif1a.txt"

    script:
        "scripts/r_scripts/hif1a_pacc.R"


rule prepare_gex_file:
    '''
    Parses the original gene expression data table to isolate only the 
    interesting columns.
    Here the columns are: patient number (46057), cdk1 (6078), epas1 (10708),
    hif1a (13533), and mki67(18766).

    To see a list of headers use: head -1 resources/GEX_46k_with_gene_names.csv | \
    tr ',' '\n' | cat -n
    '''
    input:
        original_gex = "resources/GEX_46k_with_gene_names.csv"
    
    output:
        gex = "resources/gex_interesting_genes.csv"
    
    shell:
        """
        awk -F "," 'BEGIN {{OFS="\t"}} {{print $46057,$6078,$10708,$13533,$18766}}' \
        {input.original_gex} | \
        sed 's/\r//g' > {output}
        """

rule gene_expression:
    # Adds the gene expression values to the patient data table.
    input: 
        patient_hif = "results/all_patient_unique_with_ecc_hif1a.txt", # patient data file with HIF1A activation data
        gex = "resources/gex_interesting_genes.csv", # Gene expression data of the selected genes.
        script = "scripts/patient_data_parsers/merge_gene_expression.awk" # script to merge by patient number.
    
    output:
        "results/all_patient_unique_with_ecc_hif1a_gex.txt"
    
    shell:
        """
        awk -f {input.script} {input.gex} {input.patient_hif} > {output}
        """


rule gmm_table:
    """
    Fits a two-component gaussian mixture model in all files generated in the 
    QuPath detection and generates a table with the mean of each component. 
    """
    input:
        sorted(glob.glob("resources/QuPathDetection/*A_EPCAM_measurements.txt"))
    
    output:
        "results/gmm_table.txt"
    
    script:
        "scripts/r_scripts/gaussian_mixture.R"


rule detection_table:
    # Merge the detection files created by QuPath
    input:
        sorted(glob.glob("resources/QuPathDetection/*A_EPCAM_measurements.txt"))
    output: 
        "results/all_cells_area.txt"
    shell:
        """
        awk 'BEGIN {{FS=OFS="\t"; print "Parent","Image","Area"}} 
        FNR == 1 {{next}} 
        {{
        fname = FILENAME;
        sub(/^.*\//, "", fname);  # remove the path of the file
        print fname,$1,$6}}' {input} > {output}
        """




